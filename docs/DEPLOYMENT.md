# ðŸš€ Deployment Guide

This comprehensive guide covers deploying the Intelligent Surveillance System in production environments.

## ðŸŽ¯ Deployment Overview

### Deployment Options
1. **ðŸ³ Docker Compose** - Recommended for single-node deployments
2. **â˜¸ï¸ Kubernetes** - Scalable container orchestration
3. **â˜ï¸ Cloud Platforms** - AWS, GCP, Azure managed services
4. **ðŸ–¥ï¸ Bare Metal** - Direct server installation

### Architecture Considerations
- **Load Balancing**: Distribute traffic across multiple instances
- **Auto Scaling**: Scale based on processing demand
- **High Availability**: Redundancy and failover mechanisms
- **Security**: Authentication, encryption, and access control

## ðŸ³ Docker Production Deployment

### Prerequisites
```bash
# Install Docker Engine
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Install Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```

### Production Docker Compose
Create `docker-compose.prod.yml`:

```yaml
version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.prod
    ports:
      - "8000:8000"
    environment:
      - ENV=production
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/surveillance
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
      - ./vector_db:/app/vector_db
    restart: unless-stopped
    depends_on:
      - redis
      - postgres
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    environment:
      - ENV=production
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/surveillance
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
      - ./vector_db:/app/vector_db
    restart: unless-stopped
    depends_on:
      - redis
      - postgres
    deploy:
      replicas: 2

  frontend:
    build:
      context: ./streamlit
      dockerfile: Dockerfile.prod
    ports:
      - "8501:8501"
    environment:
      - API_BASE_URL=http://api:8000
    restart: unless-stopped
    depends_on:
      - api

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=surveillance
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    ports:
      - "5432:5432"

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    restart: unless-stopped
    depends_on:
      - api
      - frontend

  monitoring:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:
```

### Production Dockerfile
Create `Dockerfile.prod`:

```dockerfile
FROM python:3.9-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    ffmpeg \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements and install Python dependencies
COPY src/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY src/ ./src/
COPY scripts/ ./scripts/

# Create necessary directories
RUN mkdir -p uploads logs vector_db

# Download AI models
RUN python -c "from ultralytics import YOLO; YOLO('yolov8n.pt')"
RUN python -c "from transformers import BlipProcessor, BlipForConditionalGeneration; BlipProcessor.from_pretrained('Salesforce/blip-image-captioning-base'); BlipForConditionalGeneration.from_pretrained('Salesforce/blip-image-captioning-base')"

# Set environment variables
ENV PYTHONPATH=/app/src
ENV ENV=production

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Start application
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### NGINX Configuration
Create `nginx.conf`:

```nginx
events {
    worker_connections 1024;
}

http {
    upstream api {
        server api:8000;
    }

    upstream frontend {
        server frontend:8501;
    }

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=upload:10m rate=2r/s;

    server {
        listen 80;
        server_name your-domain.com;
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name your-domain.com;

        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;

        # Frontend
        location / {
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # API
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            proxy_pass http://api/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Increase timeout for video uploads
            proxy_read_timeout 300s;
            proxy_send_timeout 300s;
        }

        # Upload endpoint with special rate limiting
        location /api/surveillance/upload {
            limit_req zone=upload burst=5 nodelay;
            proxy_pass http://api/surveillance/upload;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # Large file upload support
            client_max_body_size 500M;
            proxy_read_timeout 600s;
            proxy_send_timeout 600s;
        }

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header Referrer-Policy "no-referrer-when-downgrade" always;
        add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'" always;
    }
}
```

### Deployment Commands
```bash
# Build and start production services
docker-compose -f docker-compose.prod.yml up -d

# Check service status
docker-compose -f docker-compose.prod.yml ps

# View logs
docker-compose -f docker-compose.prod.yml logs -f

# Scale workers
docker-compose -f docker-compose.prod.yml up -d --scale worker=4

# Update services
docker-compose -f docker-compose.prod.yml pull
docker-compose -f docker-compose.prod.yml up -d
```

## â˜¸ï¸ Kubernetes Deployment

### Prerequisites
```bash
# Install kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# Install Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
```

### Kubernetes Manifests

#### Namespace
```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: surveillance
```

#### ConfigMap
```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: surveillance-config
  namespace: surveillance
data:
  REDIS_URL: "redis://redis:6379"
  API_BASE_URL: "http://api:8000"
  ENV: "production"
```

#### API Deployment
```yaml
# k8s/api-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: surveillance-api
  namespace: surveillance
spec:
  replicas: 3
  selector:
    matchLabels:
      app: surveillance-api
  template:
    metadata:
      labels:
        app: surveillance-api
    spec:
      containers:
      - name: api
        image: surveillance-api:latest
        ports:
        - containerPort: 8000
        envFrom:
        - configMapRef:
            name: surveillance-config
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        volumeMounts:
        - name: uploads
          mountPath: /app/uploads
        - name: vector-db
          mountPath: /app/vector_db
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: uploads
        persistentVolumeClaim:
          claimName: uploads-pvc
      - name: vector-db
        persistentVolumeClaim:
          claimName: vector-db-pvc
```

#### Worker Deployment
```yaml
# k8s/worker-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: surveillance-worker
  namespace: surveillance
spec:
  replicas: 2
  selector:
    matchLabels:
      app: surveillance-worker
  template:
    metadata:
      labels:
        app: surveillance-worker
    spec:
      containers:
      - name: worker
        image: surveillance-worker:latest
        envFrom:
        - configMapRef:
            name: surveillance-config
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
            nvidia.com/gpu: 1
          limits:
            memory: "8Gi"
            cpu: "4"
            nvidia.com/gpu: 1
        volumeMounts:
        - name: uploads
          mountPath: /app/uploads
        - name: vector-db
          mountPath: /app/vector_db
      volumes:
      - name: uploads
        persistentVolumeClaim:
          claimName: uploads-pvc
      - name: vector-db
        persistentVolumeClaim:
          claimName: vector-db-pvc
```

#### Services
```yaml
# k8s/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: surveillance-api
  namespace: surveillance
spec:
  selector:
    app: surveillance-api
  ports:
  - port: 8000
    targetPort: 8000
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: surveillance-frontend
  namespace: surveillance
spec:
  selector:
    app: surveillance-frontend
  ports:
  - port: 8501
    targetPort: 8501
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: surveillance
spec:
  selector:
    app: redis
  ports:
  - port: 6379
    targetPort: 6379
  type: ClusterIP
```

#### Ingress
```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: surveillance-ingress
  namespace: surveillance
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/proxy-body-size: "500m"
spec:
  tls:
  - hosts:
    - surveillance.your-domain.com
    secretName: surveillance-tls
  rules:
  - host: surveillance.your-domain.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: surveillance-api
            port:
              number: 8000
      - path: /
        pathType: Prefix
        backend:
          service:
            name: surveillance-frontend
            port:
              number: 8501
```

#### Horizontal Pod Autoscaler
```yaml
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: surveillance-api-hpa
  namespace: surveillance
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: surveillance-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### Deployment Commands
```bash
# Apply all manifests
kubectl apply -f k8s/

# Check deployment status
kubectl get pods -n surveillance

# Scale deployments
kubectl scale deployment surveillance-api --replicas=5 -n surveillance

# Rolling update
kubectl set image deployment/surveillance-api api=surveillance-api:v1.1.0 -n surveillance

# Check logs
kubectl logs -f deployment/surveillance-api -n surveillance
```

## â˜ï¸ Cloud Platform Deployments

### AWS ECS Deployment

#### Task Definition
```json
{
  "family": "surveillance-api",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "2048",
  "memory": "4096",
  "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::account:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "api",
      "image": "your-account.dkr.ecr.region.amazonaws.com/surveillance-api:latest",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "ENV",
          "value": "production"
        },
        {
          "name": "REDIS_URL",
          "value": "redis://elasticache-cluster.cache.amazonaws.com:6379"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/surveillance-api",
          "awslogs-region": "us-west-2",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3
      }
    }
  ]
}
```

#### Service Definition
```json
{
  "serviceName": "surveillance-api",
  "cluster": "surveillance-cluster",
  "taskDefinition": "surveillance-api:1",
  "desiredCount": 3,
  "launchType": "FARGATE",
  "networkConfiguration": {
    "awsvpcConfiguration": {
      "subnets": ["subnet-12345", "subnet-67890"],
      "securityGroups": ["sg-abcdef"],
      "assignPublicIp": "ENABLED"
    }
  },
  "loadBalancers": [
    {
      "targetGroupArn": "arn:aws:elasticloadbalancing:region:account:targetgroup/surveillance-api/1234567890",
      "containerName": "api",
      "containerPort": 8000
    }
  ]
}
```

### Google Cloud Run
```yaml
# clouddeploy.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: surveillance-api
  annotations:
    run.googleapis.com/ingress: all
    run.googleapis.com/execution-environment: gen2
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/maxScale: "10"
        run.googleapis.com/cpu-throttling: "false"
        run.googleapis.com/execution-environment: gen2
    spec:
      containerConcurrency: 100
      timeoutSeconds: 300
      containers:
      - image: gcr.io/project-id/surveillance-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: ENV
          value: production
        - name: REDIS_URL
          value: redis://redis-instance:6379
        resources:
          limits:
            cpu: 2000m
            memory: 4Gi
```

### Azure Container Apps
```yaml
# container-app.yaml
apiVersion: 2022-03-01
type: Microsoft.App/containerApps
properties:
  managedEnvironmentId: /subscriptions/{subscription}/resourceGroups/{rg}/providers/Microsoft.App/managedEnvironments/{env}
  configuration:
    ingress:
      external: true
      targetPort: 8000
    secrets:
    - name: redis-connection
      value: redis://redis-instance:6379
  template:
    containers:
    - name: surveillance-api
      image: your-registry.azurecr.io/surveillance-api:latest
      env:
      - name: ENV
        value: production
      - name: REDIS_URL
        secretRef: redis-connection
      resources:
        cpu: 2
        memory: 4Gi
    scale:
      minReplicas: 2
      maxReplicas: 10
      rules:
      - name: http-rule
        http:
          metadata:
            concurrentRequests: 50
```

## ðŸ”’ Security Configuration

### SSL/TLS Setup
```bash
# Generate SSL certificate with Let's Encrypt
sudo apt install certbot
sudo certbot certonly --standalone -d your-domain.com

# Or use DNS challenge
sudo certbot certonly --dns-cloudflare --dns-cloudflare-credentials ~/.secrets/cloudflare.ini -d your-domain.com
```

### Environment Variables
```bash
# Production environment file
cat > .env.prod << EOF
ENV=production
DEBUG=false
API_HOST=0.0.0.0
API_PORT=8000

# Database
DATABASE_URL=postgresql://user:password@db:5432/surveillance
REDIS_URL=redis://redis:6379

# Security
SECRET_KEY=your-super-secret-key-here
JWT_SECRET=another-secret-key
CORS_ORIGINS=https://your-domain.com

# AI Models
YOLO_MODEL_PATH=/app/models/yolov8n.pt
BLIP_MODEL_NAME=Salesforce/blip-image-captioning-base

# Storage
UPLOAD_DIR=/app/uploads
PROJECT_FILES_DIR=/app/project_files
VECTOR_DB_PATH=/app/vector_db
MAX_UPLOAD_SIZE=500000000

# Monitoring
SENTRY_DSN=https://your-sentry-dsn
LOG_LEVEL=INFO
EOF
```

### Firewall Configuration
```bash
# Ubuntu UFW
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow ssh
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw enable

# CentOS/RHEL Firewalld
sudo firewall-cmd --permanent --add-service=http
sudo firewall-cmd --permanent --add-service=https
sudo firewall-cmd --permanent --add-service=ssh
sudo firewall-cmd --reload
```

## ðŸ“Š Monitoring & Observability

### Prometheus Configuration
```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'surveillance-api'
    static_configs:
      - targets: ['api:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
```

### Grafana Dashboard
```json
{
  "dashboard": {
    "title": "Surveillance System",
    "panels": [
      {
        "title": "API Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Processing Queue Size",
        "type": "stat",
        "targets": [
          {
            "expr": "celery_queue_length",
            "legendFormat": "Queue Length"
          }
        ]
      }
    ]
  }
}
```

### Health Checks
```python
# monitoring/health_check.py
import requests
import time
import logging

def check_service_health():
    """Comprehensive health check for all services"""
    services = {
        'api': 'http://localhost:8000/health',
        'frontend': 'http://localhost:8501',
        'redis': 'redis://localhost:6379'
    }
    
    results = {}
    for service, url in services.items():
        try:
            if service == 'redis':
                import redis
                r = redis.from_url(url)
                r.ping()
                results[service] = 'healthy'
            else:
                response = requests.get(url, timeout=5)
                results[service] = 'healthy' if response.status_code == 200 else 'unhealthy'
        except Exception as e:
            results[service] = f'unhealthy: {str(e)}'
    
    return results

if __name__ == "__main__":
    health = check_service_health()
    print(health)
    if any(status != 'healthy' for status in health.values()):
        exit(1)
```

## ðŸ“ˆ Performance Optimization

### Load Balancing
```nginx
# NGINX load balancing
upstream api_backend {
    least_conn;
    server api1:8000 weight=3;
    server api2:8000 weight=3;
    server api3:8000 weight=2;
    
    # Health checks
    server api4:8000 backup;
}

upstream worker_backend {
    server worker1:5555;
    server worker2:5555;
    server worker3:5555;
}
```

### Caching Strategy
```python
# Redis caching configuration
CACHE_CONFIG = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://redis:6379/1',
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
            'SERIALIZER': 'django_redis.serializers.json.JSONSerializer',
            'COMPRESSOR': 'django_redis.compressors.zlib.ZlibCompressor',
        },
        'TIMEOUT': 3600,  # 1 hour
        'KEY_PREFIX': 'surveillance'
    }
}
```

### Database Optimization
```sql
-- PostgreSQL optimization
-- postgresql.conf
shared_buffers = 256MB
effective_cache_size = 1GB
maintenance_work_mem = 64MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1
effective_io_concurrency = 200

-- Indexes for performance
CREATE INDEX idx_frames_project_timestamp ON frames(project_id, timestamp);
CREATE INDEX idx_detections_class ON detections(class_name);
CREATE INDEX idx_embeddings_similarity ON embeddings USING ivfflat (embedding vector_cosine_ops);
```

## ðŸ”„ CI/CD Pipeline

### GitHub Actions
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Run tests
      run: |
        python -m pytest tests/
        
  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Build Docker image
      run: |
        docker build -t surveillance-api:${{ github.sha }} .
        docker tag surveillance-api:${{ github.sha }} surveillance-api:latest
        
    - name: Push to registry
      run: |
        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
        docker push surveillance-api:${{ github.sha }}
        docker push surveillance-api:latest
        
  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
    - name: Deploy to production
      run: |
        ssh deploy@production-server "
          cd /opt/surveillance &&
          docker-compose pull &&
          docker-compose up -d &&
          docker system prune -f
        "
```

### GitLab CI
```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy

test:
  stage: test
  script:
    - python -m pytest tests/
    - python -m black --check src/
    - python -m flake8 src/

build:
  stage: build
  script:
    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA

deploy:
  stage: deploy
  script:
    - kubectl set image deployment/surveillance-api api=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  only:
    - main
```

## ðŸ“‹ Deployment Checklist

### Pre-Deployment
- [ ] SSL certificates configured
- [ ] Environment variables set
- [ ] Database initialized
- [ ] AI models downloaded
- [ ] Monitoring configured
- [ ] Backup strategy in place
- [ ] Load testing completed

### Post-Deployment
- [ ] Health checks passing
- [ ] Monitoring alerts configured
- [ ] Log aggregation working
- [ ] Performance metrics baseline
- [ ] Security scan completed
- [ ] Documentation updated

---

**ðŸŽ‰ Your Intelligent Surveillance System is now production-ready! Monitor the system closely in the first few days and be prepared to scale based on actual usage patterns.**
